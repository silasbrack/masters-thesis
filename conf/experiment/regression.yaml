# @package _global_
trainer:
  max_epochs: 10
  accelerator: gpu
  devices: 1
  strategy:
    _target_: pytorch_lightning.strategies.ddp.DDPStrategy
    find_unused_parameters: false

defaults:
  - override /data: housing
  - override /model: linear

hydra:
  sweeper:
    params:
      model.latent_size: 128
      model.num_layers: 1,2,3,4,6,8,10
      seed: 1
      model.hessian_structure: [diag]
      model.optimize_prior_precision: [false,true]
